{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c79557e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\n",
    "    \"noticias_unificadas.tsv\",\n",
    "    encoding=\"utf-8\",\n",
    "    sep=\"\\t\",\n",
    "    dtype={\"fecha\": \"string\", \"titulo\": \"string\", \"contenido\": \"string\", \"seccion\": \"string\", \"link\": \"string\"},\n",
    "    quoting=0,\n",
    "    na_filter=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b2d13127",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total de t√≥picos √∫nicos: 7\n"
     ]
    }
   ],
   "source": [
    "topicos = df['seccion'].value_counts()\n",
    "print(f\"\\nTotal de t√≥picos √∫nicos: {df['seccion'].nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe3cd776",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fecha</th>\n",
       "      <th>titulo</th>\n",
       "      <th>contenido</th>\n",
       "      <th>seccion</th>\n",
       "      <th>link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-11-09</td>\n",
       "      <td>Jueces rechazan intento de afectaci√≥n a la ind...</td>\n",
       "      <td>Desde la ciudad de Tacna, jueces y juezas de t...</td>\n",
       "      <td>Pol√≠tica</td>\n",
       "      <td>https://diariocorreo.pe/politica/jueces-rechaz...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-11-09</td>\n",
       "      <td>Liga 1: Lo gritan los ‚ÄúChurres‚Äù y todo el pueb...</td>\n",
       "      <td>Alianza Atl√©tico le sac√≥ lustre a su clasifica...</td>\n",
       "      <td>Deportes</td>\n",
       "      <td>https://diariocorreo.pe/deportes/alianza-atlet...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-11-09</td>\n",
       "      <td>Proponen sancionar con hasta 10 a√±os de c√°rcel...</td>\n",
       "      <td>La congresista Elizabeth Medina Hermosillo, de...</td>\n",
       "      <td>Pol√≠tica</td>\n",
       "      <td>https://diariocorreo.pe/politica/proponen-sanc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-11-09</td>\n",
       "      <td>Este lunes inicia la semana de representaci√≥n ...</td>\n",
       "      <td>Desde este lunes 10 hasta el viernes 14 de nov...</td>\n",
       "      <td>Pol√≠tica</td>\n",
       "      <td>https://diariocorreo.pe/politica/este-lunes-in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-11-09</td>\n",
       "      <td>Selecci√≥n peruana eval√∫a reprogramaci√≥n de par...</td>\n",
       "      <td>La Federaci√≥n Peruana de F√∫tbol (FPF) inform√≥ ...</td>\n",
       "      <td>Deportes</td>\n",
       "      <td>https://diariocorreo.pe/deportes/seleccion-per...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        fecha                                             titulo  \\\n",
       "0  2025-11-09  Jueces rechazan intento de afectaci√≥n a la ind...   \n",
       "1  2025-11-09  Liga 1: Lo gritan los ‚ÄúChurres‚Äù y todo el pueb...   \n",
       "2  2025-11-09  Proponen sancionar con hasta 10 a√±os de c√°rcel...   \n",
       "3  2025-11-09  Este lunes inicia la semana de representaci√≥n ...   \n",
       "4  2025-11-09  Selecci√≥n peruana eval√∫a reprogramaci√≥n de par...   \n",
       "\n",
       "                                           contenido   seccion  \\\n",
       "0  Desde la ciudad de Tacna, jueces y juezas de t...  Pol√≠tica   \n",
       "1  Alianza Atl√©tico le sac√≥ lustre a su clasifica...  Deportes   \n",
       "2  La congresista Elizabeth Medina Hermosillo, de...  Pol√≠tica   \n",
       "3  Desde este lunes 10 hasta el viernes 14 de nov...  Pol√≠tica   \n",
       "4  La Federaci√≥n Peruana de F√∫tbol (FPF) inform√≥ ...  Deportes   \n",
       "\n",
       "                                                link  \n",
       "0  https://diariocorreo.pe/politica/jueces-rechaz...  \n",
       "1  https://diariocorreo.pe/deportes/alianza-atlet...  \n",
       "2  https://diariocorreo.pe/politica/proponen-sanc...  \n",
       "3  https://diariocorreo.pe/politica/este-lunes-in...  \n",
       "4  https://diariocorreo.pe/deportes/seleccion-per...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b4fcf6b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk import trigrams\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d18acfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FileSystemPathPointer('/Users/joelibaceta/nltk_data/tokenizers/punkt')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.data.find(\"tokenizers/punkt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9d731cf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FileSystemPathPointer('/Users/joelibaceta/nltk_data/tokenizers/punkt_tab')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.data.find(\"tokenizers/punkt_tab\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cc1ccf80",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, List, Tuple\n",
    "\n",
    "def tokenize_es(text: str) -> list[list[str]]:\n",
    "    if not isinstance(text, str) or not text.strip():\n",
    "        return []\n",
    "    sentences = sent_tokenize(text, language=\"spanish\")\n",
    "    tokenized = []\n",
    "    for s in sentences:\n",
    "        toks = word_tokenize(s, language=\"spanish\")\n",
    "        # lower only alphabetic tokens, keep punctuation as-is\n",
    "        toks = [t.lower() if t.isalpha() else t for t in toks]\n",
    "        if toks:\n",
    "            tokenized.append(toks)\n",
    "    return tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b1ced0ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def load_corpus(df: pd.DataFrame, by_category: bool = False) -> Dict[str, List[List[str]]]:\n",
    "    buckets: Dict[str, List[List[str]]] = defaultdict(list)\n",
    "    \n",
    "    for _, row in df.iterrows():\n",
    "        categoria = (row.get(\"seccion\") or \"\").strip()\n",
    "        noticia = row.get(\"contenido\")\n",
    "        \n",
    "        if not noticia or not isinstance(noticia, str):\n",
    "            continue\n",
    "            \n",
    "        sents_toks = tokenize_es(noticia)\n",
    "        \n",
    "        if by_category and categoria:\n",
    "            for s in sents_toks:\n",
    "                if s:\n",
    "                    buckets[categoria].append(s)\n",
    "        else:\n",
    "            for s in sents_toks:\n",
    "                if s:\n",
    "                    buckets[\"_GLOBAL\"].append(s)\n",
    "    \n",
    "    return buckets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "52213eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_por_categoria = load_corpus(df, by_category=True)\n",
    "corpus_global = load_corpus(df, by_category=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b5cfedbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_trigrams(tokenized_sentences: List[List[str]]):\n",
    "    \"\"\"\n",
    "      model[(w1,w2)][w3] = prob\n",
    "    \"\"\"\n",
    "    model = defaultdict(lambda: defaultdict(float))\n",
    "    for sent in tokenized_sentences:\n",
    "        for w1, w2, w3 in trigrams(sent, pad_left=True, pad_right=True):\n",
    "            model[(w1, w2)][w3] += 1.0\n",
    "\n",
    "    for w1w2 in model:\n",
    "        total = sum(model[w1w2].values())\n",
    "        if total > 0:\n",
    "            for w3 in model[w1w2]:\n",
    "                model[w1w2][w3] /= total\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "00c23821",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2274244"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_global = train_trigrams(corpus_global[\"_GLOBAL\"])\n",
    "len(model_global)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d0aefaa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenando modelo para: Pol√≠tica (164273 oraciones)\n",
      "Entrenando modelo para: Deportes (64217 oraciones)\n",
      "Entrenando modelo para: Deportes (64217 oraciones)\n",
      "Entrenando modelo para: Espect√°culos (95589 oraciones)\n",
      "Entrenando modelo para: Espect√°culos (95589 oraciones)\n",
      "Entrenando modelo para: Cultura (82146 oraciones)\n",
      "Entrenando modelo para: Cultura (82146 oraciones)\n",
      "Entrenando modelo para: Econom√≠a (56308 oraciones)\n",
      "Entrenando modelo para: Econom√≠a (56308 oraciones)\n",
      "Entrenando modelo para: Mundo (81657 oraciones)\n",
      "Entrenando modelo para: Mundo (81657 oraciones)\n",
      "Entrenando modelo para: Policiales (50687 oraciones)\n",
      "Entrenando modelo para: Policiales (50687 oraciones)\n"
     ]
    }
   ],
   "source": [
    "models_por_categoria = {}\n",
    "\n",
    "for categoria, oraciones in corpus_por_categoria.items():\n",
    "    print(f\"Entrenando modelo para: {categoria} ({len(oraciones)} oraciones)\")\n",
    "    models_por_categoria[categoria] = train_trigrams(oraciones)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1c7e5bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "import random\n",
    "\n",
    "def sample_next(model: dict, w1: str, w2: str) -> Optional[str]:\n",
    "    dist = model.get((w1, w2), {})\n",
    "    if not dist:\n",
    "        for ctx in [(None, w2), (w1, None), (None, None)]:\n",
    "            dist = model.get(ctx, {})\n",
    "            if dist:\n",
    "                break\n",
    "        if not dist:\n",
    "            return None\n",
    "\n",
    "    r = random.random()\n",
    "    acc = 0.0\n",
    "    for w3, p in dist.items():\n",
    "        acc += p\n",
    "        if acc >= r:\n",
    "            return w3\n",
    "    return next(iter(dist.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3586a027",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sentence(model: dict, seeds: Tuple[str, str] = (None, None), max_len: int = 30) -> str:\n",
    "    text: List[str] = [seeds[0], seeds[1]]\n",
    "    sentence_finished = False\n",
    "\n",
    "    while not sentence_finished and len(text) < max_len + 2:\n",
    "        w3 = sample_next(model, text[-2], text[-1])\n",
    "        text.append(w3)\n",
    "        if text[-2:] == [None, None] or w3 is None:\n",
    "            sentence_finished = True\n",
    "\n",
    "    sentence = \" \".join([t for t in text if t])\n",
    "    sentence = sentence.strip()\n",
    "    if sentence and sentence[-1] not in \".!?\":\n",
    "        sentence += \".\"\n",
    "    if sentence:\n",
    "        sentence = sentence[0].upper() + sentence[1:]\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "92ae162a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_paragraph(model: dict, n_sentences: int = 3, seeds: Tuple[str, str] = (None, None)) -> str:\n",
    "    return \" \".join(generate_sentence(model, seeds=seeds) for _ in range(n_sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "62c0af79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La Policia ojal√° que los c√°lculos del usda estim√≥ una tasa de crecimiento y la primera en dar un paso firme hacia la ventana . La Policia `` esta organizaci√≥n '' . La Policia es de dos premios internacionales , como dijo un testigo a la escritora peruana : quita estr√©s ‚Äì two broders + salsipuedes brewing co ( new york times public√≥ el.\n"
     ]
    }
   ],
   "source": [
    "print(generate_paragraph(model_global, n_sentences=3, seeds=(\"La\", \"Policia\", )))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c1e17e84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El equipo juvenil mixto ( nataci√≥n y haber encontrado un equipo argentino para sellar la clasificaci√≥n general , por copa libertadores y la paradeportista , niurka callupe ( femenino ) ? El equipo que se arm√≥ en colombia , c√©sar vallejo su desvinculaci√≥n del -ahora- exdirector t√©cnico de la derrota por ippon ante el sampdoria por la semifinal . El equipo que cay√≥ ante su pr√≥ximo desaf√≠o ser√° visitar a la primera dificultad log√≠stica que enfrentar√° al ganador . El equipo libre ¬øQu√© es el principal objetivo es campeonar .\n"
     ]
    }
   ],
   "source": [
    "print(generate_paragraph(models_por_categoria[\"Deportes\"], n_sentences=4, seeds=(\"El\", \"equipo\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "25399f45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "POL√çTICA:\n",
      "El presidente , que elimina movimientos regionales y locales , abarrotaban plazas y todo lo que aumenta m√°s cada a√±o se sortear√°n 842,000 miembros de mi cliente y le hemos cambiado de. El presidente de la colisi√≥n entre una y dos bomberos lesionadoshuancayo : cajera es detenida por apoderarse de S/26 milxi jinping : ‚Äú ahora √©l es quien investiga y que , a. El presidente alan garc√≠a , un espect√°culo de conflicto ‚Äù , p√©rez no quer√≠an perder m√°s del 41 , y el bloque democr√°tico popular , avanza pa√≠s , y humberto mi√±√°n almanza.\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nPOL√çTICA:\")\n",
    "print(generate_paragraph(models_por_categoria[\"Pol√≠tica\"], n_sentences=3, seeds=(\"El\", \"presidente\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc9d12dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generate_sentence(model: dict, seeds: Tuple[str, str] = (None, None), max_len: int = 30) -> str:\n",
    "\n",
    "    # Normalizar seeds a min√∫sculas si no son None\n",
    "    w1 = seeds[0].lower() if seeds[0] else None\n",
    "    w2 = seeds[1].lower() if seeds[1] else None\n",
    "    \n",
    "    # Iniciar la secuencia\n",
    "    text: List[str] = []\n",
    "    if w1:\n",
    "        text.append(w1)\n",
    "    if w2:\n",
    "        text.append(w2)\n",
    "    \n",
    "    # Si no hay seeds, empezar desde el inicio de oraci√≥n\n",
    "    if not text:\n",
    "        w1, w2 = None, None\n",
    "    elif len(text) == 1:\n",
    "        w1, w2 = None, text[0]\n",
    "    else:\n",
    "        w1, w2 = text[-2], text[-1]\n",
    "    \n",
    "    sentence_finished = False\n",
    "    \n",
    "    while not sentence_finished and len(text) < max_len:\n",
    "        w3 = sample_next(model, w1, w2)\n",
    "        \n",
    "        # Terminar si encontramos el marcador de fin o no hay siguiente palabra\n",
    "        if w3 is None:\n",
    "            sentence_finished = True\n",
    "        else:\n",
    "            text.append(w3)\n",
    "            w1, w2 = w2, w3\n",
    "    \n",
    "    # Construir la oraci√≥n\n",
    "    sentence = \" \".join([t for t in text if t])\n",
    "    sentence = sentence.strip()\n",
    "    \n",
    "    # Agregar punto final si no tiene puntuaci√≥n\n",
    "    if sentence and sentence[-1] not in \".!?\":\n",
    "        sentence += \".\"\n",
    "    \n",
    "    # Capitalizar primera letra\n",
    "    if sentence:\n",
    "        sentence = sentence[0].upper() + sentence[1:]\n",
    "    \n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e9ba95ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_paragraph(model: dict, n_sentences: int = 3, seeds: Tuple[str, str] = (None, None)) -> str:\n",
    "    \"\"\"\n",
    "    Genera un p√°rrafo de m√∫ltiples oraciones.\n",
    "    Solo usa las seeds para la primera oraci√≥n.\n",
    "    \"\"\"\n",
    "    sentences = []\n",
    "    # Primera oraci√≥n usa las seeds\n",
    "    sentences.append(generate_sentence(model, seeds=seeds))\n",
    "    \n",
    "    # Resto de oraciones sin seeds (comienzan naturalmente)\n",
    "    for _ in range(n_sentences - 1):\n",
    "        sentences.append(generate_sentence(model, seeds=(None, None)))\n",
    "    \n",
    "    return \" \".join(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8f39ec9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La polic√≠a encontr√≥ varios casquillos de bala . Varias de estas , el ministerio p√∫blico . Era ni√±o , al igual que ahora lo hace a trav√©s del tiempo , atziri se desplom√≥ sobre el exgobernador regional de ayacucho ? para empezar , solo se regulariza.\n"
     ]
    }
   ],
   "source": [
    "print(generate_paragraph(model_global, n_sentences=3, seeds=(\"La\", \"polic√≠a\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ec5f00f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEPORTES - Seeds: ('El', 'equipo')\n",
      "El equipo que cambien el ‚Äú submarino amarillo ‚Äô saca 6 puntos en lo individual y persecuci√≥n por equipos . Per√∫21 epaper . Directo al mundial 2026 . B√∫scanos en yape !\n"
     ]
    }
   ],
   "source": [
    "print(\"DEPORTES - Seeds: ('El', 'equipo')\")\n",
    "print(generate_paragraph(models_por_categoria[\"Deportes\"], n_sentences=4, seeds=(\"El\", \"equipo\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "46dc13e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POL√çTICA - Seeds: ('El', 'presidente')\n",
      "El presidente de jp en el escenario internacional , y alucinando un encuentro con pamela l√≥pez en discoteca durante concierto de la denunciante.La denuncia fue formulada formalmente por la contralor√≠a general viene. Estar a tu casa como garant√≠a de motivaci√≥n , ya que tiene categor√≠a de distinci√≥n para diferenciar entre los diferentes poderes del estado , ya que anteriormente hab√≠a tenido expresiones. El texto sustitutorio del proyecto especial regional pasto grande , porque el 24 de febrero , ecuador , seg√∫n ‚Äò panorama ‚Äô , boluarte asegur√≥ que su gesti√≥n busca potenciar.\n"
     ]
    }
   ],
   "source": [
    "print(\"POL√çTICA - Seeds: ('El', 'presidente')\")\n",
    "print(generate_paragraph(models_por_categoria[\"Pol√≠tica\"], n_sentences=3, seeds=(\"El\", \"presidente\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c6bab921",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODELO GLOBAL - Sin seeds (inicio natural)\n",
      "¬°Ahora disponible en yape ! ¬øQUI√âN es yessenia lozano millones , aproximadamente 120 millones ) . Zelenski afirm√≥ el consejo empresarial Peruano-Japon√©s ( cepeja ) , natalia salas confes√≥ que su presunto c√≥mplice fue atrapado por la octava jornada de las devociones m√°s poderosas para inculcar.\n"
     ]
    }
   ],
   "source": [
    "print(\"MODELO GLOBAL - Sin seeds (inicio natural)\")\n",
    "print(generate_paragraph(model_global, n_sentences=3, seeds=(None, None)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65f96db8",
   "metadata": {},
   "source": [
    "## üìä An√°lisis: Combinaciones m√°s frecuentes (Trigramas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "691e15cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def get_most_frequent_trigrams(tokenized_sentences: List[List[str]], top_n: int = 20, exclude_padding: bool = True):\n",
    "    \"\"\"\n",
    "    Identifica los trigramas m√°s frecuentes en el corpus.\n",
    "    \n",
    "    Args:\n",
    "        tokenized_sentences: Lista de oraciones tokenizadas\n",
    "        top_n: N√∫mero de trigramas a retornar\n",
    "        exclude_padding: Si True, excluye trigramas que contienen None (padding)\n",
    "    \n",
    "    Returns:\n",
    "        Lista de tuplas ((w1, w2, w3), frecuencia)\n",
    "    \"\"\"\n",
    "    trigram_counts = Counter()\n",
    "    \n",
    "    for sent in tokenized_sentences:\n",
    "        for w1, w2, w3 in trigrams(sent, pad_left=True, pad_right=True):\n",
    "            # Opcionalmente excluir trigramas con padding\n",
    "            if exclude_padding and (w1 is None or w2 is None or w3 is None):\n",
    "                continue\n",
    "            trigram_counts[(w1, w2, w3)] += 1\n",
    "    \n",
    "    return trigram_counts.most_common(top_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6c9b6c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "TRIGRAMAS M√ÅS FRECUENTES - CORPUS GLOBAL\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"TRIGRAMAS M√ÅS FRECUENTES - CORPUS GLOBAL\")\n",
    "\n",
    "top_trigrams_global = get_most_frequent_trigrams(corpus_global[\"_GLOBAL\"], top_n=30)\n",
    "\n",
    "for i, ((w1, w2, w3), freq) in enumerate(top_trigrams_global, 1):\n",
    "    w1_str = f\"'{w1}'\" if w1 else \"None\"\n",
    "    w2_str = f\"'{w2}'\" if w2 else \"None\"\n",
    "    w3_str = f\"'{w3}'\" if w3 else \"None\"\n",
    "    \n",
    "    print(f\"{i:2}. ({w1_str:>15}, {w2_str:>15}, {w3_str:>15}) ‚Üí {freq:>5} veces\")\n",
    "\n",
    "print(f\"\\nTotal de trigramas √∫nicos: {len(set(trigrams(sum(corpus_global['_GLOBAL'], []), pad_left=True, pad_right=True)))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde73b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analizar por categor√≠a\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"TRIGRAMAS M√ÅS FRECUENTES POR CATEGOR√çA\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "for categoria in [\"Deportes\", \"Pol√≠tica\", \"Econom√≠a\"]:\n",
    "    if categoria in corpus_por_categoria:\n",
    "        print(f\"\\nüìÇ {categoria.upper()}\")\n",
    "        print(\"-\" * 70)\n",
    "        \n",
    "        top_trigrams = get_most_frequent_trigrams(\n",
    "            corpus_por_categoria[categoria], \n",
    "            top_n=10, \n",
    "            exclude_padding=True\n",
    "        )\n",
    "        \n",
    "        for i, ((w1, w2, w3), freq) in enumerate(top_trigrams, 1):\n",
    "            print(f\"  {i:2}. ({w1}, {w2}, {w3}) ‚Üí {freq} veces\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f21d057",
   "metadata": {},
   "source": [
    "### Visualizaci√≥n de trigramas frecuentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91651eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_top_trigrams(trigrams_list, title=\"Top Trigramas\", top_n=15):\n",
    "    \"\"\"\n",
    "    Visualiza los trigramas m√°s frecuentes en un gr√°fico de barras.\n",
    "    \"\"\"\n",
    "    # Tomar solo los top_n\n",
    "    trigrams_list = trigrams_list[:top_n]\n",
    "    \n",
    "    # Preparar datos\n",
    "    labels = [f\"{w1} {w2} {w3}\" for (w1, w2, w3), _ in trigrams_list]\n",
    "    frequencies = [freq for _, freq in trigrams_list]\n",
    "    \n",
    "    # Crear gr√°fico\n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "    bars = ax.barh(range(len(labels)), frequencies, color='steelblue', alpha=0.8)\n",
    "    \n",
    "    ax.set_yticks(range(len(labels)))\n",
    "    ax.set_yticklabels(labels, fontsize=10)\n",
    "    ax.set_xlabel('Frecuencia', fontsize=12, fontweight='bold')\n",
    "    ax.set_title(title, fontsize=14, fontweight='bold', pad=20)\n",
    "    ax.invert_yaxis()\n",
    "    ax.grid(axis='x', alpha=0.3)\n",
    "    \n",
    "    # Agregar valores al final de las barras\n",
    "    for i, (bar, freq) in enumerate(zip(bars, frequencies)):\n",
    "        ax.text(freq + 0.5, i, str(freq), va='center', fontsize=9, fontweight='bold')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Visualizar trigramas del corpus global\n",
    "plot_top_trigrams(top_trigrams_global, title=\"Top 15 Trigramas - Corpus Global\", top_n=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6701aa0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparaci√≥n entre categor√≠as\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "fig.suptitle('Trigramas M√°s Frecuentes por Categor√≠a', fontsize=16, fontweight='bold', y=0.995)\n",
    "\n",
    "categorias_plot = [\"Deportes\", \"Pol√≠tica\", \"Econom√≠a\", \"Internacional\"]\n",
    "axes_flat = axes.flatten()\n",
    "\n",
    "for idx, categoria in enumerate(categorias_plot):\n",
    "    if categoria in corpus_por_categoria:\n",
    "        top_cat = get_most_frequent_trigrams(\n",
    "            corpus_por_categoria[categoria], \n",
    "            top_n=10, \n",
    "            exclude_padding=True\n",
    "        )\n",
    "        \n",
    "        labels = [f\"{w1} {w2} {w3}\" for (w1, w2, w3), _ in top_cat]\n",
    "        frequencies = [freq for _, freq in top_cat]\n",
    "        \n",
    "        ax = axes_flat[idx]\n",
    "        bars = ax.barh(range(len(labels)), frequencies, color='coral', alpha=0.7)\n",
    "        ax.set_yticks(range(len(labels)))\n",
    "        ax.set_yticklabels(labels, fontsize=9)\n",
    "        ax.set_xlabel('Frecuencia', fontsize=10)\n",
    "        ax.set_title(f'üìÇ {categoria}', fontsize=12, fontweight='bold')\n",
    "        ax.invert_yaxis()\n",
    "        ax.grid(axis='x', alpha=0.3)\n",
    "        \n",
    "        # Valores en las barras\n",
    "        for i, (bar, freq) in enumerate(zip(bars, frequencies)):\n",
    "            ax.text(freq + 0.3, i, str(freq), va='center', fontsize=8)\n",
    "    else:\n",
    "        axes_flat[idx].text(0.5, 0.5, f'Categor√≠a \"{categoria}\"\\nno disponible', \n",
    "                           ha='center', va='center', transform=axes_flat[idx].transAxes)\n",
    "        axes_flat[idx].set_xticks([])\n",
    "        axes_flat[idx].set_yticks([])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "007f8ab6",
   "metadata": {},
   "source": [
    "### An√°lisis adicional: Bigramas m√°s frecuentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "366562a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import bigrams\n",
    "\n",
    "def get_most_frequent_bigrams(tokenized_sentences: List[List[str]], top_n: int = 20, exclude_padding: bool = True):\n",
    "    \"\"\"\n",
    "    Identifica los bigramas m√°s frecuentes en el corpus.\n",
    "    \"\"\"\n",
    "    bigram_counts = Counter()\n",
    "    \n",
    "    for sent in tokenized_sentences:\n",
    "        for w1, w2 in bigrams(sent, pad_left=True, pad_right=True):\n",
    "            if exclude_padding and (w1 is None or w2 is None):\n",
    "                continue\n",
    "            bigram_counts[(w1, w2)] += 1\n",
    "    \n",
    "    return bigram_counts.most_common(top_n)\n",
    "\n",
    "# Analizar bigramas\n",
    "print(\"=\" * 70)\n",
    "print(\"BIGRAMAS M√ÅS FRECUENTES - CORPUS GLOBAL\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "top_bigrams = get_most_frequent_bigrams(corpus_global[\"_GLOBAL\"], top_n=30, exclude_padding=True)\n",
    "\n",
    "for i, ((w1, w2), freq) in enumerate(top_bigrams, 1):\n",
    "    print(f\"{i:2}. ('{w1}', '{w2}') ‚Üí {freq:>5} veces\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "292bb7a7",
   "metadata": {},
   "source": [
    "### üìà Interpretaci√≥n de resultados\n",
    "\n",
    "Los trigramas m√°s frecuentes te muestran:\n",
    "1. **Patrones comunes** en el lenguaje period√≠stico espa√±ol\n",
    "2. **Frases t√≠picas** que se repiten en las noticias\n",
    "3. **Contextos espec√≠ficos** de cada categor√≠a (deportes, pol√≠tica, etc.)\n",
    "\n",
    "Esto es √∫til para:\n",
    "- Entender qu√© combinaciones de palabras son m√°s naturales\n",
    "- Mejorar la generaci√≥n de texto (el modelo aprende de estas frecuencias)\n",
    "- Identificar vocabulario caracter√≠stico de cada tem√°tica"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
